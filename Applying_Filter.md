## ğŸŸ¥ Applying Filter

### ğŸ“· Python Code (8_blur_avg_kernel.py)

```python
import cv2
import numpy as np

img = cv2.imread('../img/city.jpg')
'''
#5x5 í‰ê·  í•„í„° ì»¤ë„ ìƒì„±    ---â‘ 
kernel = np.array([[0.04, 0.04, 0.04, 0.04, 0.04],
                   [0.04, 0.04, 0.04, 0.04, 0.04],
                   [0.04, 0.04, 0.04, 0.04, 0.04],
                   [0.04, 0.04, 0.04, 0.04, 0.04],
                   [0.04, 0.04, 0.04, 0.04, 0.04]])
'''
# 5x5 í‰ê·  í•„í„° ì»¤ë„ ìƒì„±  ---â‘¡
kernel = np.ones((5,5))/5**2
# í•„í„° ì ìš©             ---â‘¢
blured = cv2.filter2D(img, -1, kernel)

# ê²°ê³¼ ì¶œë ¥
cv2.imshow('origin', img)
cv2.imshow('avrg blur', blured) 
cv2.waitKey()
cv2.destroyAllWindows()

```

### ğŸ“· **Result Screenshot:**

![Result](result_screenshot/8.jpg)
<br>

---

<br>

### ğŸ“· Python Code (9_blur_avg_api.py)

```python
import cv2
import numpy as np

file_name = '../img/jinx.jpg'
img = cv2.imread(file_name)

# blur() í•¨ìˆ˜ë¡œ ë¸”ëŸ¬ë§  ---â‘ 
blur1 = cv2.blur(img, (10,10))
# boxFilter() í•¨ìˆ˜ë¡œ ë¸”ëŸ¬ë§ ì ìš© ---â‘¡
blur2 = cv2.boxFilter(img, -1, (10,10))

# ê²°ê³¼ ì¶œë ¥
merged = np.hstack( (img, blur1, blur2))
cv2.imshow('blur', merged)
cv2.waitKey(0)
cv2.destroyAllWindows()

```

### ğŸ“· **Result Screenshot:**

![Result](result_screenshot/9.jpg)
<br>

---

<br>

### ğŸ“· Python Code (10_blur_gaussian.py)

```python
import cv2
import numpy as np

img = cv2.imread('../img/gaussian_noise.jpg')

# ê°€ìš°ì‹œì•ˆ ì»¤ë„ì„ ì§ì ‘ ìƒì„±í•´ì„œ ë¸”ëŸ¬ë§  ---â‘ 
k1 = np.array([[1, 2, 1],
                   [2, 4, 2],
                   [1, 2, 1]]) *(1/16)
blur1 = cv2.filter2D(img, -1, k1)

# ê°€ìš°ì‹œì•ˆ ì»¤ë„ì„ APIë¡œ ì–»ì–´ì„œ ë¸”ëŸ¬ë§ ---â‘¡
k2 = cv2.getGaussianKernel(3, 0)
blur2 = cv2.filter2D(img, -1, k2*k2.T)

# ê°€ìš°ì‹œì•ˆ ë¸”ëŸ¬ APIë¡œ ë¸”ëŸ¬ë§ ---â‘¢
blur3 = cv2.GaussianBlur(img, (3, 3), 0)

# ê²°ê³¼ ì¶œë ¥
print('k1:', k1)
print('k2:', k2*k2.T)
merged = np.hstack((img, blur1, blur2, blur3))
cv2.imshow('gaussian blur', merged)
cv2.waitKey(0)
cv2.destroyAllWindows()

```

### ğŸ“· **Result Screenshot:**

![Result](result_screenshot/10.jpg)
<br>

---

<br>

### ğŸ“· Python Code (11_blur_median.py)

```python
import cv2
import numpy as np

img = cv2.imread("../img/salt_pepper_noise.jpg")

# ë¯¸ë””ì–¸ ë¸”ëŸ¬ ì ìš© --- â‘ 
blur = cv2.medianBlur(img, 5)

# ê²°ê³¼ ì¶œë ¥ 
merged = np.hstack((img,blur))
cv2.imshow('media', merged)
cv2.waitKey(0)
cv2.destroyAllWindows()

```

### ğŸ“· **Result Screenshot:**

![Result](result_screenshot/11.jpg)
<br>

---

<br>

### ğŸ“· Python Code (12_blur_bilateral.py)

```python
import cv2
import numpy as np

img = cv2.imread("../img/gaussian_noise.jpg")

# ê°€ìš°ì‹œì•ˆ í•„í„° ì ìš© ---â‘ 
blur1 = cv2.GaussianBlur(img, (5,5), 0)

# ë°”ì´ë ˆí„°ëŸ´ í•„í„° ì ìš© ---â‘¡
blur2 = cv2.bilateralFilter(img, 5, 75, 75)

# ê²°ê³¼ ì¶œë ¥
merged = np.hstack((img, blur1, blur2))
cv2.imshow('bilateral', merged)
cv2.waitKey(0)
cv2.destroyAllWindows()

```

### ğŸ“· **Result Screenshot:**

![Result](result_screenshot/12.jpg)
<br>

---

<br>

### ğŸ“· Python Code (13_edge_differential.py)

```python
import cv2
import numpy as np

img = cv2.imread("../img/sudoku.jpg")

#ë¯¸ë¶„ ì»¤ë„ ìƒì„± ---â‘ 
gx_kernel = np.array([[ -1, 1]])
gy_kernel = np.array([[ -1],[ 1]])

# í•„í„° ì ìš© ---â‘¡
edge_gx = cv2.filter2D(img, -1, gx_kernel)
edge_gy = cv2.filter2D(img, -1, gy_kernel)
# ê²°ê³¼ ì¶œë ¥
merged = np.hstack((img, edge_gx, edge_gy))
cv2.imshow('edge', merged)
cv2.waitKey(0)
cv2.destroyAllWindows()

```

### ğŸ“· **Result Screenshot:**

![Result](result_screenshot/13.jpg)
<br>

---

<br>

### ğŸ“· Python Code (14_edge_canny.py)

```python
import cv2, time
import numpy as np

img = cv2.imread("../img/sudoku.jpg")

# ì¼€ë‹ˆ ì—£ì§€ ì ìš© 
edges = cv2.Canny(img,100,200)

# ê²°ê³¼ ì¶œë ¥
cv2.imshow('Original', img)
cv2.imshow('Canny', edges)
cv2.waitKey(0)
cv2.destroyAllWindows()

```

### ğŸ“· **Result Screenshot:**

![Result](result_screenshot/14.jpg)
<br>

---

<br>

### ğŸ“· Python Code (15_practice02.py)

```python
# ìë™ì°¨ ë²ˆí˜¸íŒ ì¶”ì¶œí•´ë‚´ê¸° ìˆ˜ì •íŒ
# í•„í„°ë¥¼ ì ìš©í•´ì„œ ì´ë¯¸ì§€ ë…¸ì´ì¦ˆ ì œê±° ë° ê²½ê³„ ê²€ì¶œ

import cv2
import numpy as np
from matplotlib import pyplot as plt
import os

# ì¶”ì¶œëœ ë²ˆí˜¸íŒ ì´ë¯¸ì§€ ë¡œë“œ
def load_extracted_plate(plate_name):
    plate_path = f'../img/{plate_name}.jpg'

    if os.path.exists(plate_path):
        plate_img = cv2.imread(plate_path)
        print(f"ë²ˆí˜¸íŒ ì´ë¯¸ì§€ ë¡œë“œ ì™„ë£Œ: {plate_img.shape}")
        return plate_img

    else:
        print(f"íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {plate_path}")
        return None
        
# ë²ˆí˜¸íŒì„ ê·¸ë ˆì´ìŠ¤ì¼€ì¼ë¡œ ë³€í™˜
def convert_to_grayscale(plate_img):
    # BGRì„ ê·¸ë ˆì´ìŠ¤ì¼€ì¼ë¡œ ë³€í™˜
    gray_plate = cv2.cvtColor(plate_img, cv2.COLOR_BGR2GRAY)

    # ê²°ê³¼ ë¹„êµ ì‹œê°í™”
    plt.figure(figsize=(12, 4))
    plt.subplot(1, 2, 1)
    plt.imshow(cv2.cvtColor(plate_img, cv2.COLOR_BGR2RGB))
    plt.title('Original Extracted Plate')
    plt.axis('off')
    plt.subplot(1, 2, 2)
    plt.imshow(gray_plate, cmap='gray')
    plt.title('Grayscale Plate')
    plt.axis('off')
    plt.tight_layout()
    plt.show()

    return gray_plate

# ë²ˆí˜¸íŒì˜ ê¸€ì ëŒ€ë¹„ ìµœëŒ€í™”
def maximize_contrast(gray_plate):
    # ëª¨í´ë¡œì§€ ì—°ì‚°ìš© êµ¬ì¡°í™” ìš”ì†Œ (ë²ˆí˜¸íŒìš©ìœ¼ë¡œ ì‘ê²Œ ì„¤ì •)
    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (2, 2))  # 3x3 â†’ 2x2ë¡œ ì¶•ì†Œ

    # Top Hat: ë°ì€ ì„¸ë¶€ì‚¬í•­ (í° ë°°ê²½) ê°•ì¡°
    tophat = cv2.morphologyEx(gray_plate, cv2.MORPH_TOPHAT, kernel)

    # Black Hat: ì–´ë‘ìš´ ì„¸ë¶€ì‚¬í•­ (ê²€ì€ ê¸€ì) ê°•ì¡°  
    blackhat = cv2.morphologyEx(gray_plate, cv2.MORPH_BLACKHAT, kernel)

    # ëŒ€ë¹„ í–¥ìƒ ì ìš©
    enhanced = cv2.add(gray_plate, tophat)
    enhanced = cv2.subtract(enhanced, blackhat)

    # ì¶”ê°€: íˆìŠ¤í† ê·¸ë¨ ê· ë“±í™”ë¡œ ëŒ€ë¹„ ë”ìš± í–¥ìƒ
    enhanced = cv2.equalizeHist(enhanced)

    # ê²°ê³¼ ë¹„êµ
    plt.figure(figsize=(15, 4))
    plt.subplot(1, 4, 1)
    plt.imshow(gray_plate, cmap='gray')
    plt.title('Original Gray')
    plt.axis('off')
    plt.subplot(1, 4, 2)
    plt.imshow(tophat, cmap='gray')
    plt.title('Top Hat')
    plt.axis('off')
    plt.subplot(1, 4, 3)
    plt.imshow(blackhat, cmap='gray')
    plt.title('Black Hat')
    plt.axis('off')
    plt.subplot(1, 4, 4)
    plt.imshow(enhanced, cmap='gray')
    plt.title('Enhanced Contrast')
    plt.axis('off')
    plt.tight_layout()
    plt.show()

    return enhanced

# ê³ ê¸‰ ëŒ€ë¹„ í–¥ìƒ ê¸°ë²•
def advanced_contrast_enhancement(gray_plate):
     # CLAHE (ì ì‘í˜• íˆìŠ¤í† ê·¸ë¨ ê· ë“±í™”)
    clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(2,1))  # ë²ˆí˜¸íŒìš© ì„¤ì •
    clahe_result = clahe.apply(gray_plate)

    # ê°ë§ˆ ë³´ì •
    gamma = 1.2  # ë°ê¸° ì¡°ì •
    gamma_corrected = np.array(255 * (gray_plate / 255) ** gamma, dtype='uint8')

    return clahe_result, gamma_corrected

# ë²ˆí˜¸íŒ ì „ìš© ì ì‘í˜• ì„ê³„ì²˜ë¦¬
def adaptive_threshold_plate(enhanced_plate):
    # ê°€ë²¼ìš´ ë¸”ëŸ¬ë§ (ë…¸ì´ì¦ˆ ì œê±°, ê¸€ìëŠ” ë³´ì¡´)
    blurred = cv2.GaussianBlur(enhanced_plate, (3, 3), 0)  # 5x5 â†’ 3x3ë¡œ ì¶•ì†Œ

    # ë²ˆí˜¸íŒ ìµœì í™” ì ì‘í˜• ì„ê³„ì²˜ë¦¬
    thresh_adaptive = cv2.adaptiveThreshold(
        blurred,
        maxValue=255,
        adaptiveMethod=cv2.ADAPTIVE_THRESH_GAUSSIAN_C,
        thresholdType=cv2.THRESH_BINARY,  # BINARY_INV ëŒ€ì‹  BINARY ì‚¬ìš©
        blockSize=11,  # 19 â†’ 11ë¡œ ì¶•ì†Œ (ë²ˆí˜¸íŒ í¬ê¸°ì— ë§ì¶¤)
        C=2           # 9 â†’ 2ë¡œ ì¶•ì†Œ (ì„¸ë°€í•œ ì¡°ì •)
    )

    # Otsu ì„ê³„ì²˜ë¦¬ì™€ ë¹„êµ
    _, thresh_otsu = cv2.threshold(blurred, 0, 255, 
                                   cv2.THRESH_BINARY + cv2.THRESH_OTSU)

    # ê²°ê³¼ ë¹„êµ
    plt.figure(figsize=(16, 4))
    plt.subplot(1, 4, 1)
    plt.imshow(enhanced_plate, cmap='gray')
    plt.title('Enhanced Plate')
    plt.axis('off')
    plt.subplot(1, 4, 2)
    plt.imshow(blurred, cmap='gray')
    plt.title('Blurred')
    plt.axis('off')
    plt.subplot(1, 4, 3)
    plt.imshow(thresh_adaptive, cmap='gray')
    plt.title('Adaptive Threshold')
    plt.axis('off')
    plt.subplot(1, 4, 4)
    plt.imshow(thresh_otsu, cmap='gray')
    plt.title('Otsu Threshold')
    plt.axis('off')
    plt.tight_layout()
    plt.show()

    return thresh_adaptive, thresh_otsu

# ë²ˆí˜¸íŒì—ì„œ ìœ¤ê³½ì„  ê²€ì¶œ
def find_contours_in_plate(thresh_plate):
    # ìœ¤ê³½ì„  ê²€ì¶œ
    contours, hierarchy = cv2.findContours(
        thresh_plate,                   # ì´ì§„í™”ëœ ë²ˆí˜¸íŒ ì´ë¯¸ì§€
        mode=cv2.RETR_EXTERNAL,         # ê°€ì¥ ë°”ê¹¥ìª½ ìœ¤ê³½ì„ ë§Œ ê²€ì¶œ
        method=cv2.CHAIN_APPROX_SIMPLE  # ìœ¤ê³½ì„  ë‹¨ìˆœí™”
    )

    # ê²°ê³¼ ì‹œê°í™”ìš© ì´ë¯¸ì§€ ìƒì„± (ì»¬ëŸ¬)
    height, width = thresh_plate.shape
    contour_image = cv2.cvtColor(thresh_plate, cv2.COLOR_GRAY2BGR)

    # ëª¨ë“  ìœ¤ê³½ì„ ì„ ë‹¤ë¥¸ ìƒ‰ìœ¼ë¡œ ê·¸ë¦¬ê¸°
    colors = [(255, 0, 0), (0, 255, 0), (0, 0, 255), (255, 255, 0), 
              (255, 0, 255), (0, 255, 255), (128, 0, 128), (255, 165, 0)]

    for i, contour in enumerate(contours):
        color = colors[i % len(colors)]  # ìƒ‰ìƒ ìˆœí™˜
        cv2.drawContours(contour_image, [contour], -1, color, 2)

        # ìœ¤ê³½ì„  ë²ˆí˜¸ í‘œì‹œ
        M = cv2.moments(contour)
        if M["m00"] != 0:
            cx = int(M["m10"] / M["m00"])
            cy = int(M["m01"] / M["m00"])
            cv2.putText(contour_image, str(i+1), (cx-5, cy+5), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.4, (255, 255, 255), 1)

    # ê²°ê³¼ ì‹œê°í™”
    plt.figure(figsize=(15, 5))
    plt.subplot(1, 3, 1)
    plt.imshow(thresh_plate, cmap='gray')
    plt.title('Binary Plate')
    plt.axis('off')
    plt.subplot(1, 3, 2)
    plt.imshow(contour_image)
    plt.title(f'Contours Detected: {len(contours)}')
    plt.axis('off')

    # ìœ¤ê³½ì„  ì •ë³´ í‘œì‹œ
    plt.subplot(1, 3, 3)
    contour_info = np.zeros((height, width, 3), dtype=np.uint8)

    for i, contour in enumerate(contours):
        area = cv2.contourArea(contour)
        x, y, w, h = cv2.boundingRect(contour)

        # ê²½ê³„ ì‚¬ê°í˜• ê·¸ë¦¬ê¸°
        cv2.rectangle(contour_info, (x, y), (x+w, y+h), colors[i % len(colors)], 1)

        # ë©´ì  ì •ë³´ í‘œì‹œ (ì‘ì€ ê¸€ì”¨ë¡œ)
        cv2.putText(contour_info, f'A:{int(area)}', (x, y-2), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.25, (255, 255, 255), 1)

    plt.imshow(contour_info)
    plt.title('Bounding Rectangles')
    plt.axis('off')
    plt.tight_layout()
    plt.show()

    # ìœ¤ê³½ì„  ì •ë³´ ì¶œë ¥
    print("=== ìœ¤ê³½ì„  ê²€ì¶œ ê²°ê³¼ ===")
    print(f"ì´ ìœ¤ê³½ì„  ê°œìˆ˜: {len(contours)}")

    for i, contour in enumerate(contours):
        area = cv2.contourArea(contour)
        x, y, w, h = cv2.boundingRect(contour)
        aspect_ratio = w / h if h > 0 else 0
        print(f"ìœ¤ê³½ì„  {i+1}: ë©´ì ={area:.0f}, \
              í¬ê¸°=({w}Ã—{h}), ë¹„ìœ¨={aspect_ratio:.2f}")

    return contours, contour_image

# ë‹¤ì–‘í•œ ìœ¤ê³½ì„  ê²€ì¶œ ëª¨ë“œ ë¹„êµ
def compare_contour_modes(thresh_plate):
    # ì—¬ëŸ¬ ëª¨ë“œë¡œ ìœ¤ê³½ì„  ê²€ì¶œ
    modes = [
        (cv2.RETR_EXTERNAL, "EXTERNAL"),
        (cv2.RETR_LIST, "LIST"), 
        (cv2.RETR_TREE, "TREE")
    ]

    plt.figure(figsize=(15, 5))

    for i, (mode, mode_name) in enumerate(modes):
        contours, _ = cv2.findContours(thresh_plate, mode, cv2.CHAIN_APPROX_SIMPLE)
        result_img = cv2.cvtColor(thresh_plate, cv2.COLOR_GRAY2BGR)
        cv2.drawContours(result_img, contours, -1, (0, 255, 0), 1)

        plt.subplot(1, 3, i+1)
        plt.imshow(result_img)
        plt.title(f'{mode_name}: {len(contours)} contours')
        plt.axis('off')

    plt.tight_layout()
    plt.show()

# ìœ¤ê³½ì„  í†µê³„ ë¶„ì„
def analyze_contour_statistics(contours):
    if len(contours) == 0:
        print("ê²€ì¶œëœ ìœ¤ê³½ì„ ì´ ì—†ìŠµë‹ˆë‹¤.")
        return

    areas = [cv2.contourArea(contour) for contour in contours]
    perimeters = [cv2.arcLength(contour, True) for contour in contours]

    print("=== ìœ¤ê³½ì„  í†µê³„ ===")
    print(f"ê°œìˆ˜: {len(contours)}")
    print(f"ë©´ì  - í‰ê· : {np.mean(areas):.1f}, \
          ìµœì†Œ: {min(areas):.1f}, ìµœëŒ€: {max(areas):.1f}")
    print(f"ë‘˜ë ˆ - í‰ê· : {np.mean(perimeters):.1f}, \
          ìµœì†Œ: {min(perimeters):.1f}, ìµœëŒ€: {max(perimeters):.1f}")

    # ë©´ì ë³„ ë¶„í¬
    area_ranges = [(0, 50), (50, 200), (200, 500), (500, 1000), (1000, float('inf'))]

    for min_area, max_area in area_ranges:
        count = sum(1 for area in areas if min_area <= area < max_area)
        if count > 0:
            range_str = f"{min_area}-{max_area if max_area != float('inf') else 'âˆ'}"
            print(f"ë©´ì  {range_str}: {count}ê°œ")

# ë‹¤ìŒ ë‹¨ê³„(ê¸€ì ë¶„ì„)ë¥¼ ìœ„í•œ ê¸°ë³¸ ì •ë³´ ì¤€ë¹„
def prepare_for_next_step(contours, thresh_plate):
    print("=== ë‹¤ìŒ ë‹¨ê³„ ì¤€ë¹„ ===")

    # ìœ¤ê³½ì„ ì´ ì¶©ë¶„íˆ ê²€ì¶œë˜ì—ˆëŠ”ì§€ í™•ì¸
    if len(contours) < 5:
        print("ìœ¤ê³½ì„ ì´ ì ê²Œ ê²€ì¶œë˜ì—ˆìŠµë‹ˆë‹¤. ì „ì²˜ë¦¬ ë‹¨ê³„ë¥¼ ì¬ê²€í† í•˜ì„¸ìš”.")

    elif len(contours) > 20:
        print("ìœ¤ê³½ì„ ì´ ë„ˆë¬´ ë§ì´ ê²€ì¶œë˜ì—ˆìŠµë‹ˆë‹¤. ë…¸ì´ì¦ˆ ì œê±°ê°€ í•„ìš”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

    else:
        print("ì ì ˆí•œ ìˆ˜ì˜ ìœ¤ê³½ì„ ì´ ê²€ì¶œë˜ì—ˆìŠµë‹ˆë‹¤.")

    # ì ì¬ì  ê¸€ì í›„ë³´ ê°œìˆ˜ ì¶”ì •
    potential_chars = 0

    for contour in contours:
        area = cv2.contourArea(contour)

        if 30 < area < 2000:  # ê¸€ì í¬ê¸° ë²”ìœ„ ì¶”ì •
            potential_chars += 1

    print(f"ì ì¬ì  ê¸€ì í›„ë³´: {potential_chars}ê°œ")

    return potential_chars

# ì²˜ë¦¬ëœ ë²ˆí˜¸íŒ ì´ë¯¸ì§€ë“¤ì„ ì²´ê³„ì ìœ¼ë¡œ ì €ì¥
def save_processed_results(plate_name, gray_plate, 
                           enhanced_plate, thresh_plate, 
                           contour_result):
    # ì €ì¥ í´ë” ìƒì„±
    save_dir = '../result_screenshot/plates_number'

    if not os.path.exists(save_dir):
        os.makedirs(save_dir) 

    # ê° ë‹¨ê³„ë³„ ê²°ê³¼ ì €ì¥
    cv2.imwrite(f'{save_dir}/{plate_name}_1_gray.jpg', gray_plate)
    cv2.imwrite(f'{save_dir}/{plate_name}_2_enhanced.jpg', enhanced_plate)  
    cv2.imwrite(f'{save_dir}/{plate_name}_3_threshold.jpg', thresh_plate)
    cv2.imwrite(f'{save_dir}/{plate_name}_4_contours.jpg', contour_result)

    print(f"ì²˜ë¦¬ ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {save_dir}/{plate_name}_*.jpg")

# ì „ì²´ ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸
# ì¶”ì¶œëœ ë²ˆí˜¸íŒì˜ ì™„ì „í•œ ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸
def process_extracted_plate(plate_name):
    print(f"=== {plate_name} ì²˜ë¦¬ ì‹œì‘ ===")

    # ì´ë¯¸ì§€ ë¡œë“œ
    plate_img = load_extracted_plate(plate_name)

    if plate_img is None:
        return None

    # ê·¸ë ˆì´ìŠ¤ì¼€ì¼ ë³€í™˜
    gray_plate = convert_to_grayscale(plate_img)

    # ëŒ€ë¹„ ìµœëŒ€í™”
    enhanced_plate = maximize_contrast(gray_plate)

    # ì ì‘í˜• ì„ê³„ì²˜ë¦¬
    thresh_plate, _ = adaptive_threshold_plate(enhanced_plate)

    # ìœ¤ê³½ì„  ê²€ì¶œ
    contours, contour_result = find_contours_in_plate(thresh_plate)

    # ê²°ê³¼ ì €ì¥
    save_processed_results(plate_name, gray_plate, enhanced_plate, thresh_plate, contour_result)

    # ì²˜ë¦¬ ê²°ê³¼ ìš”ì•½
    potential_chars = prepare_for_next_step(contours, thresh_plate)
    print(f"ì²˜ë¦¬ ì™„ë£Œ - ê²€ì¶œëœ ìœ¤ê³½ì„ : {len(contours)}ê°œ, ì ì¬ì  ê¸€ì: {potential_chars}ê°œ")

    return {
        'original': plate_img,
        'gray': gray_plate, 
        'enhanced': enhanced_plate,
        'threshold': thresh_plate,
        'contours': len(contours),
        'potential_chars': potential_chars,
        'contour_result': contour_result
    }

# ë°°ì¹˜ ì²˜ë¦¬
# img í´ë”ì˜ ëª¨ë“  ë²ˆí˜¸íŒ ì²˜ë¦¬
def batch_process_plates():
    plate_dir = '../img'

    if not os.path.exists(plate_dir):
        print(f"í´ë”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {plate_dir}")
        return {}

    plate_files = [f for f in os.listdir(plate_dir) if f.endswith('.jpg')]

    if len(plate_files) == 0:
        print("ì²˜ë¦¬í•  ë²ˆí˜¸íŒ ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return {}

    results = {}

    for plate_file in plate_files:
        plate_name = plate_file.replace('.jpg', '')
        result = process_extracted_plate(plate_name)

        if result:
            results[plate_name] = result

    print(f"\n=== ì „ì²´ ì²˜ë¦¬ ì™„ë£Œ: {len(results)}ê°œ ë²ˆí˜¸íŒ ===")

    return results


# í„°ë¯¸ë„ì„ í†µí•´ ì°¨ëŸ‰ ë²ˆí˜¸íŒ ê°¯ìˆ˜ ì…ë ¥
car_num = int(input("ë²ˆí˜¸íŒ ìŠ¤ìº”í•˜ë ¤ëŠ” ì°¨ëŸ‰ì˜ ê°¯ìˆ˜ë¥¼ ì…ë ¥í•˜ì‹œì˜¤: "))
for i in range(1, car_num+1):
    img = cv2.imread(f"../img/car_{i}.jpg")
    win_name = f"scanning_{i}"
    rows, cols = img.shape[:2]
    draw = img.copy()
    pts_cnt = 0
    pts = np.zeros((4,2), dtype=np.float32)

    # ë§ˆìš°ìŠ¤ ì´ë²¤íŠ¸ callback í•¨ìˆ˜ êµ¬í˜„
    def onMouse(event, x, y, flags, param):
        # ë§ˆìš°ìŠ¤ë¡œ ì°ì€ ì¢Œí‘œ ê°¯ìˆ˜ ì €ì¥
        global  pts_cnt
        if event == cv2.EVENT_LBUTTONDOWN:
            # ì¢Œí‘œì— ì´ˆë¡ìƒ‰ ë™ê·¸ë¼ë¯¸ í‘œì‹œ
            cv2.circle(draw, (x,y), 10, (0,255,0), -1)
            cv2.imshow(win_name, draw)

            # ë§ˆìš°ìŠ¤ ì¢Œí‘œ ì €ì¥
            pts[pts_cnt] = [x,y]
            pts_cnt+=1

            # ì¢Œí‘œê°€ 4ê°œ ìˆ˜ì§‘ë˜ë©´
            if pts_cnt == 4:
                # ì¢Œí‘œ 4ê°œ ì¤‘ ìƒí•˜ì¢Œìš° ì°¾ê¸°
                sm = pts.sum(axis=1)                # 4ìŒì˜ ì¢Œí‘œ ê°ê° x+y ê³„ì‚°
                diff = np.diff(pts, axis = 1)       # 4ìŒì˜ ì¢Œí‘œ ê°ê° x-y ê³„ì‚°

                topLeft = pts[np.argmin(sm)]        # x+yê°€ ê°€ì¥ ê°’ì´ ì¢Œìƒë‹¨ ì¢Œí‘œ
                bottomRight = pts[np.argmax(sm)]    # x+yê°€ ê°€ì¥ í° ê°’ì´ ìš°í•˜ë‹¨ ì¢Œí‘œ
                topRight = pts[np.argmin(diff)]     # x-yê°€ ê°€ì¥ ì‘ì€ ê²ƒì´ ìš°ìƒë‹¨ ì¢Œí‘œ
                bottomLeft = pts[np.argmax(diff)]   # x-yê°€ ê°€ì¥ í° ê°’ì´ ì¢Œí•˜ë‹¨ ì¢Œí‘œ

                # ë³€í™˜ ì „ 4ê°œ ì¢Œí‘œ 
                pts1 = np.float32([topLeft, topRight, bottomRight , bottomLeft])

                # ë³€í™˜ í›„ ì˜ìƒì— ì‚¬ìš©í•  ì„œë¥˜ì˜ í­ê³¼ ë†’ì´ ê³„ì‚°
                w1 = abs(bottomRight[0] - bottomLeft[0])    # ìƒë‹¨ ì¢Œìš° ì¢Œí‘œê°„ì˜ ê±°ë¦¬
                w2 = abs(topRight[0] - topLeft[0])          # í•˜ë‹¹ ì¢Œìš° ì¢Œí‘œê°„ì˜ ê±°ë¦¬
                h1 = abs(topRight[1] - bottomRight[1])      # ìš°ì¸¡ ìƒí•˜ ì¢Œí‘œê°„ì˜ ê±°ë¦¬
                h2 = abs(topLeft[1] - bottomLeft[1])        # ì¢Œì¸¡ ìƒí•˜ ì¢Œí‘œê°„ì˜ ê±°ë¦¬
                width = max([w1, w2])                       # ë‘ ì¢Œìš° ê±°ë¦¬ê°„ì˜ ìµœëŒ€ê°’ì´ ì„œë¥˜ì˜ í­
                height = max([h1, h2])                      # ë‘ ìƒí•˜ ê±°ë¦¬ê°„ì˜ ìµœëŒ€ê°’ì´ ì„œë¥˜ì˜ ë†’ì´
            
                # ë³€í™˜ í›„ 4ê°œ ì¢Œí‘œ
                pts2 = np.float32([[0,0], [width-1,0], 
                                   [width-1,height-1], [0,height-1]])

                # ë³€í™˜ í–‰ë ¬ ê³„ì‚° 
                mtrx = cv2.getPerspectiveTransform(pts1, pts2)
                # ì›ê·¼ ë³€í™˜ ì ìš©
                result = cv2.warpPerspective(img, mtrx, 
                                             (int(width), int(height)))  # ì£¼ì˜! í•´ìƒë„ ì ìš© ì‹œ, intë¥¼ ì§€ì •í•´ì¤˜ì•¼ í•¨!
                cv2.imshow('scanned', result)
                cv2.imwrite(f'../img/car_scanned_{i}.jpg', result)

    cv2.imshow(win_name, img)
    # ë§ˆìš°ìŠ¤ callback í•¨ìˆ˜ë¥¼ GUI ìœˆë„ìš°ì— ë“±ë¡
    cv2.setMouseCallback(win_name, onMouse)
    cv2.waitKey(0)
    # ì‹¤ ì‚¬ì§„ íŒŒì¼ ì´ë¦„ ì…ë ¥
    plate_result = process_extracted_plate(f'car_scanned_{i}')
    cv2.waitKey(0)

cv2.destroyAllWindows()

```

### ğŸ“· **Result Screenshot:**

car_scanned_1.jpg

![Result](img/car_scanned_1.jpg)
<br>

car_scanned_1_1_gray.jpg

![Result](result_screenshot/plates_number/car_scanned_1_1_gray.jpg)
<br>

car_scanned_1_2_enhanced.jpg

![Result](result_screenshot/plates_number/car_scanned_1_2_enhanced.jpg)
<br>

car_scanned_1_3_threshold.jpg

![Result](result_screenshot/plates_number/car_scanned_1_3_threshold.jpg)
<br>

car_scanned_1_4_contours.jpg

![Result](result_screenshot/plates_number/car_scanned_1_4_contours.jpg)
<br>

---

<br>

